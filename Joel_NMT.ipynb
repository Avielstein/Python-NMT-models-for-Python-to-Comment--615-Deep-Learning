{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deluxe-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ##### Copyright 2019 The TensorFlow Authors.\n",
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Adapted from https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "committed-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/des338/Workspace/NLP/PythonCommentGenerataor\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "DB_FILE = '../code_and_comments/all_data.db'\n",
    "NUM_EXAMPLES = 10000\n",
    "SPLIT = 8000\n",
    "EXAMPLE_LENGTH_CAP = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mediterranean-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿();=:])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything not listed below with space\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿();=:]+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helpful-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> format batch script from vars <end>\n",
      "b'<start> def get batch script ( self , subvars ) : colud be overridden by subclasses , but mainly useful for testing return format template ( self . batch script , subvars ) <end>'\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(DB_FILE)\n",
    "c = conn.cursor()\n",
    "# Filter down to short-ish python examples\n",
    "pairs = c.execute('SELECT * FROM all_data WHERE filename LIKE \"%.py\" AND ' + 'length(code) < {0} AND length(comment) < {0} LIMIT {1}'.format(EXAMPLE_LENGTH_CAP, NUM_EXAMPLES))\n",
    "pairs = [i[1:] for i in pairs.fetchall()]\n",
    "\n",
    "source_sentence = pairs[0][0]\n",
    "target_sentence = pairs[0][1]\n",
    "print(preprocess_sentence(target_sentence))\n",
    "print(preprocess_sentence(source_sentence).encode('utf-8'))\n",
    "\n",
    "target = [preprocess_sentence(i[1]) for i in pairs]\n",
    "source = [preprocess_sentence(i[0]) for i in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pharmaceutical-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(targ_lang, inp_lang, num_examples=NUM_EXAMPLES):\n",
    "    # creating cleaned input, output pairs\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-montana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(target, source, NUM_EXAMPLES)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "# This line was crashing for me, not sure why, just replaced with slices for now\n",
    "#input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "input_tensor_train = input_tensor[:SPLIT]\n",
    "input_tensor_val = input_tensor[SPLIT:]\n",
    "target_tensor_train = target_tensor[:SPLIT]\n",
    "target_tensor_val = target_tensor[SPLIT:]\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "combined-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "certain-george",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "7 ----> <start>\n",
      "9 ----> def\n",
      "12 ----> get\n",
      "590 ----> batch\n",
      "368 ----> script\n",
      "2 ----> (\n",
      "4 ----> self\n",
      "6 ----> ,\n",
      "3486 ----> subvars\n",
      "1 ----> )\n",
      "5 ----> :\n",
      "5156 ----> colud\n",
      "398 ----> be\n",
      "2803 ----> overridden\n",
      "92 ----> by\n",
      "2804 ----> subclasses\n",
      "6 ----> ,\n",
      "1834 ----> but\n",
      "5157 ----> mainly\n",
      "5158 ----> useful\n",
      "19 ----> for\n",
      "1057 ----> testing\n",
      "11 ----> return\n",
      "76 ----> format\n",
      "232 ----> template\n",
      "2 ----> (\n",
      "4 ----> self\n",
      "3 ----> .\n",
      "590 ----> batch\n",
      "368 ----> script\n",
      "6 ----> ,\n",
      "3486 ----> subvars\n",
      "1 ----> )\n",
      "8 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "126 ----> format\n",
      "1137 ----> batch\n",
      "600 ----> script\n",
      "30 ----> from\n",
      "2275 ----> vars\n",
      "3 ----> <end>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 83]), TensorShape([128, 62]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "# dynamically grow GPU memory\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "signal-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informative-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (128, 83, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "endless-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "characteristic-asset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (128, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (128, 83, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "turkish-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "common-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 6843)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
    "\n",
    "# ## Define the optimizer and the loss function\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "private-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tender-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Checkpoints (Object-based saving)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "canadian-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Training\n",
    "# \n",
    "# 1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "# 2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "# 3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "# 4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "# 5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "# 6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "# 7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate.\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "grand-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.0164\n",
      "Epoch 2 Batch 0 Loss 1.2599\n",
      "Epoch 2 Loss 0.0203\n",
      "Time taken for 1 epoch 1.1595051288604736 sec\n",
      "\n",
      "Epoch 2 Loss 0.0393\n",
      "Time taken for 1 epoch 2.301675319671631 sec\n",
      "\n",
      "Epoch 2 Loss 0.0576\n",
      "Time taken for 1 epoch 3.4237751960754395 sec\n",
      "\n",
      "Epoch 2 Loss 0.0774\n",
      "Time taken for 1 epoch 4.534507989883423 sec\n",
      "\n",
      "Epoch 2 Loss 0.0996\n",
      "Time taken for 1 epoch 5.640337705612183 sec\n",
      "\n",
      "Epoch 2 Loss 0.1217\n",
      "Time taken for 1 epoch 6.781972885131836 sec\n",
      "\n",
      "Epoch 2 Loss 0.1432\n",
      "Time taken for 1 epoch 7.90011739730835 sec\n",
      "\n",
      "Epoch 2 Loss 0.1663\n",
      "Time taken for 1 epoch 9.014917612075806 sec\n",
      "\n",
      "Epoch 2 Loss 0.1892\n",
      "Time taken for 1 epoch 10.145364761352539 sec\n",
      "\n",
      "Epoch 2 Loss 0.2096\n",
      "Time taken for 1 epoch 11.289396524429321 sec\n",
      "\n",
      "Epoch 2 Loss 0.2327\n",
      "Time taken for 1 epoch 12.399291753768921 sec\n",
      "\n",
      "Epoch 2 Loss 0.2569\n",
      "Time taken for 1 epoch 13.509204149246216 sec\n",
      "\n",
      "Epoch 2 Loss 0.2784\n",
      "Time taken for 1 epoch 14.622074842453003 sec\n",
      "\n",
      "Epoch 2 Loss 0.3013\n",
      "Time taken for 1 epoch 15.727023839950562 sec\n",
      "\n",
      "Epoch 2 Loss 0.3202\n",
      "Time taken for 1 epoch 16.803602933883667 sec\n",
      "\n",
      "Epoch 2 Loss 0.3414\n",
      "Time taken for 1 epoch 17.92369055747986 sec\n",
      "\n",
      "Epoch 2 Loss 0.3607\n",
      "Time taken for 1 epoch 19.03613543510437 sec\n",
      "\n",
      "Epoch 2 Loss 0.3817\n",
      "Time taken for 1 epoch 20.113288164138794 sec\n",
      "\n",
      "Epoch 2 Loss 0.4026\n",
      "Time taken for 1 epoch 21.227471828460693 sec\n",
      "\n",
      "Epoch 2 Loss 0.4247\n",
      "Time taken for 1 epoch 22.34610104560852 sec\n",
      "\n",
      "Epoch 2 Loss 0.4475\n",
      "Time taken for 1 epoch 23.46402668952942 sec\n",
      "\n",
      "Epoch 2 Loss 0.4680\n",
      "Time taken for 1 epoch 24.587757110595703 sec\n",
      "\n",
      "Epoch 2 Loss 0.4882\n",
      "Time taken for 1 epoch 25.67212462425232 sec\n",
      "\n",
      "Epoch 2 Loss 0.5091\n",
      "Time taken for 1 epoch 26.75731110572815 sec\n",
      "\n",
      "Epoch 2 Loss 0.5333\n",
      "Time taken for 1 epoch 27.868942260742188 sec\n",
      "\n",
      "Epoch 2 Loss 0.5544\n",
      "Time taken for 1 epoch 28.981461763381958 sec\n",
      "\n",
      "Epoch 2 Loss 0.5762\n",
      "Time taken for 1 epoch 30.056196689605713 sec\n",
      "\n",
      "Epoch 2 Loss 0.5963\n",
      "Time taken for 1 epoch 31.131498098373413 sec\n",
      "\n",
      "Epoch 2 Loss 0.6161\n",
      "Time taken for 1 epoch 32.246079206466675 sec\n",
      "\n",
      "Epoch 2 Loss 0.6396\n",
      "Time taken for 1 epoch 33.36867594718933 sec\n",
      "\n",
      "Epoch 2 Loss 0.6594\n",
      "Time taken for 1 epoch 34.46760869026184 sec\n",
      "\n",
      "Epoch 2 Loss 0.6807\n",
      "Time taken for 1 epoch 35.581302642822266 sec\n",
      "\n",
      "Epoch 2 Loss 0.7011\n",
      "Time taken for 1 epoch 36.687910079956055 sec\n",
      "\n",
      "Epoch 2 Loss 0.7231\n",
      "Time taken for 1 epoch 37.769861936569214 sec\n",
      "\n",
      "Epoch 2 Loss 0.7443\n",
      "Time taken for 1 epoch 38.88285493850708 sec\n",
      "\n",
      "Epoch 2 Loss 0.7659\n",
      "Time taken for 1 epoch 40.22076201438904 sec\n",
      "\n",
      "Epoch 2 Loss 0.7888\n",
      "Time taken for 1 epoch 41.32464551925659 sec\n",
      "\n",
      "Epoch 2 Loss 0.8093\n",
      "Time taken for 1 epoch 42.44488501548767 sec\n",
      "\n",
      "Epoch 2 Loss 0.8282\n",
      "Time taken for 1 epoch 43.56342911720276 sec\n",
      "\n",
      "Epoch 2 Loss 0.8492\n",
      "Time taken for 1 epoch 44.681177377700806 sec\n",
      "\n",
      "Epoch 2 Loss 0.8699\n",
      "Time taken for 1 epoch 45.79789996147156 sec\n",
      "\n",
      "Epoch 2 Loss 0.8912\n",
      "Time taken for 1 epoch 46.9171986579895 sec\n",
      "\n",
      "Epoch 2 Loss 0.9128\n",
      "Time taken for 1 epoch 48.04286599159241 sec\n",
      "\n",
      "Epoch 2 Loss 0.9344\n",
      "Time taken for 1 epoch 49.24775838851929 sec\n",
      "\n",
      "Epoch 2 Loss 0.9558\n",
      "Time taken for 1 epoch 50.719531297683716 sec\n",
      "\n",
      "Epoch 2 Loss 0.9777\n",
      "Time taken for 1 epoch 52.1566743850708 sec\n",
      "\n",
      "Epoch 2 Loss 0.9968\n",
      "Time taken for 1 epoch 53.28061628341675 sec\n",
      "\n",
      "Epoch 2 Loss 1.0178\n",
      "Time taken for 1 epoch 54.70571851730347 sec\n",
      "\n",
      "Epoch 2 Loss 1.0393\n",
      "Time taken for 1 epoch 55.813047885894775 sec\n",
      "\n",
      "Epoch 2 Loss 1.0582\n",
      "Time taken for 1 epoch 57.69659638404846 sec\n",
      "\n",
      "Epoch 2 Loss 1.0790\n",
      "Time taken for 1 epoch 58.81836175918579 sec\n",
      "\n",
      "Epoch 2 Loss 1.0978\n",
      "Time taken for 1 epoch 60.1956262588501 sec\n",
      "\n",
      "Epoch 2 Loss 1.1178\n",
      "Time taken for 1 epoch 62.171852350234985 sec\n",
      "\n",
      "Epoch 2 Loss 1.1415\n",
      "Time taken for 1 epoch 63.52136445045471 sec\n",
      "\n",
      "Epoch 2 Loss 1.1612\n",
      "Time taken for 1 epoch 65.19972920417786 sec\n",
      "\n",
      "Epoch 2 Loss 1.1803\n",
      "Time taken for 1 epoch 66.62579488754272 sec\n",
      "\n",
      "Epoch 2 Loss 1.2021\n",
      "Time taken for 1 epoch 68.33979725837708 sec\n",
      "\n",
      "Epoch 2 Loss 1.2226\n",
      "Time taken for 1 epoch 70.03290891647339 sec\n",
      "\n",
      "Epoch 2 Loss 1.2426\n",
      "Time taken for 1 epoch 71.72479367256165 sec\n",
      "\n",
      "Epoch 2 Loss 1.2623\n",
      "Time taken for 1 epoch 73.42956018447876 sec\n",
      "\n",
      "Epoch 2 Loss 1.2824\n",
      "Time taken for 1 epoch 75.4522922039032 sec\n",
      "\n",
      "Epoch 2 Loss 1.3041\n",
      "Time taken for 1 epoch 77.39662861824036 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.2806\n",
      "Epoch 4 Batch 0 Loss 1.1961\n",
      "Epoch 4 Loss 0.0193\n",
      "Time taken for 1 epoch 1.1393895149230957 sec\n",
      "\n",
      "Epoch 4 Loss 0.0388\n",
      "Time taken for 1 epoch 2.266101121902466 sec\n",
      "\n",
      "Epoch 4 Loss 0.0559\n",
      "Time taken for 1 epoch 3.3897411823272705 sec\n",
      "\n",
      "Epoch 4 Loss 0.0754\n",
      "Time taken for 1 epoch 4.520483493804932 sec\n",
      "\n",
      "Epoch 4 Loss 0.0932\n",
      "Time taken for 1 epoch 5.639954566955566 sec\n",
      "\n",
      "Epoch 4 Loss 0.1118\n",
      "Time taken for 1 epoch 6.753549098968506 sec\n",
      "\n",
      "Epoch 4 Loss 0.1318\n",
      "Time taken for 1 epoch 7.880123138427734 sec\n",
      "\n",
      "Epoch 4 Loss 0.1499\n",
      "Time taken for 1 epoch 9.00679326057434 sec\n",
      "\n",
      "Epoch 4 Loss 0.1685\n",
      "Time taken for 1 epoch 10.110512971878052 sec\n",
      "\n",
      "Epoch 4 Loss 0.1883\n",
      "Time taken for 1 epoch 11.225503921508789 sec\n",
      "\n",
      "Epoch 4 Loss 0.2066\n",
      "Time taken for 1 epoch 12.305979490280151 sec\n",
      "\n",
      "Epoch 4 Loss 0.2238\n",
      "Time taken for 1 epoch 13.389288187026978 sec\n",
      "\n",
      "Epoch 4 Loss 0.2413\n",
      "Time taken for 1 epoch 14.494757652282715 sec\n",
      "\n",
      "Epoch 4 Loss 0.2594\n",
      "Time taken for 1 epoch 15.613681316375732 sec\n",
      "\n",
      "Epoch 4 Loss 0.2771\n",
      "Time taken for 1 epoch 16.74573850631714 sec\n",
      "\n",
      "Epoch 4 Loss 0.2963\n",
      "Time taken for 1 epoch 17.857055187225342 sec\n",
      "\n",
      "Epoch 4 Loss 0.3148\n",
      "Time taken for 1 epoch 18.98481822013855 sec\n",
      "\n",
      "Epoch 4 Loss 0.3329\n",
      "Time taken for 1 epoch 20.107439517974854 sec\n",
      "\n",
      "Epoch 4 Loss 0.3510\n",
      "Time taken for 1 epoch 21.299442768096924 sec\n",
      "\n",
      "Epoch 4 Loss 0.3705\n",
      "Time taken for 1 epoch 22.54198908805847 sec\n",
      "\n",
      "Epoch 4 Loss 0.3897\n",
      "Time taken for 1 epoch 23.918752908706665 sec\n",
      "\n",
      "Epoch 4 Loss 0.4091\n",
      "Time taken for 1 epoch 25.003906726837158 sec\n",
      "\n",
      "Epoch 4 Loss 0.4264\n",
      "Time taken for 1 epoch 26.799252033233643 sec\n",
      "\n",
      "Epoch 4 Loss 0.4464\n",
      "Time taken for 1 epoch 27.910887718200684 sec\n",
      "\n",
      "Epoch 4 Loss 0.4639\n",
      "Time taken for 1 epoch 29.246156692504883 sec\n",
      "\n",
      "Epoch 4 Loss 0.4813\n",
      "Time taken for 1 epoch 30.87590527534485 sec\n",
      "\n",
      "Epoch 4 Loss 0.5001\n",
      "Time taken for 1 epoch 32.57822060585022 sec\n",
      "\n",
      "Epoch 4 Loss 0.5197\n",
      "Time taken for 1 epoch 34.25949168205261 sec\n",
      "\n",
      "Epoch 4 Loss 0.5394\n",
      "Time taken for 1 epoch 35.962276458740234 sec\n",
      "\n",
      "Epoch 4 Loss 0.5598\n",
      "Time taken for 1 epoch 37.64320969581604 sec\n",
      "\n",
      "Epoch 4 Loss 0.5778\n",
      "Time taken for 1 epoch 39.46241116523743 sec\n",
      "\n",
      "Epoch 4 Loss 0.5978\n",
      "Time taken for 1 epoch 41.30717754364014 sec\n",
      "\n",
      "Epoch 4 Loss 0.6169\n",
      "Time taken for 1 epoch 43.1912317276001 sec\n",
      "\n",
      "Epoch 4 Loss 0.6350\n",
      "Time taken for 1 epoch 45.04317116737366 sec\n",
      "\n",
      "Epoch 4 Loss 0.6541\n",
      "Time taken for 1 epoch 47.05618691444397 sec\n",
      "\n",
      "Epoch 4 Loss 0.6720\n",
      "Time taken for 1 epoch 49.59086346626282 sec\n",
      "\n",
      "Epoch 4 Loss 0.6915\n",
      "Time taken for 1 epoch 51.27164936065674 sec\n",
      "\n",
      "Epoch 4 Loss 0.7097\n",
      "Time taken for 1 epoch 52.96335697174072 sec\n",
      "\n",
      "Epoch 4 Loss 0.7301\n",
      "Time taken for 1 epoch 54.65504741668701 sec\n",
      "\n",
      "Epoch 4 Loss 0.7500\n",
      "Time taken for 1 epoch 56.42701554298401 sec\n",
      "\n",
      "Epoch 4 Loss 0.7688\n",
      "Time taken for 1 epoch 58.323222637176514 sec\n",
      "\n",
      "Epoch 4 Loss 0.7865\n",
      "Time taken for 1 epoch 60.28752255439758 sec\n",
      "\n",
      "Epoch 4 Loss 0.8049\n",
      "Time taken for 1 epoch 62.21827697753906 sec\n",
      "\n",
      "Epoch 4 Loss 0.8216\n",
      "Time taken for 1 epoch 64.09484004974365 sec\n",
      "\n",
      "Epoch 4 Loss 0.8402\n",
      "Time taken for 1 epoch 65.95903539657593 sec\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "training_checkpoints/ckpt-108_temp_abe1f266e52848b7bc2fc95e9e6af8c1/part-00001-of-00002.data-00000-of-00001.tempstate3313762762830324598; No space left on device [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SaveV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3d126db48858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# saving (checkpoint) the model every 2 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m   1925\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0mcheckpoint_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s-%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1928\u001b[0m     checkpoint_management.update_checkpoint_state_internal(\n\u001b[1;32m   1929\u001b[0m         \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m   1855\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \"\"\"\n\u001b[0;32m-> 1857\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1858\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0m\u001b[1;32m   1187\u001b[0m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1134\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m         return save_v2_eager_fallback(\n\u001b[0m\u001b[1;32m   1707\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             ctx=_ctx)\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1727\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0m\u001b[1;32m   1730\u001b[0m                              ctx=ctx, name=name)\n\u001b[1;32m   1731\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: training_checkpoints/ckpt-108_temp_abe1f266e52848b7bc2fc95e9e6af8c1/part-00001-of-00002.data-00000-of-00001.tempstate3313762762830324598; No space left on device [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 6\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "        # saving (checkpoint) the model every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "            print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                              total_loss / steps_per_epoch))\n",
    "            print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Translate\n",
    "# \n",
    "# * The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "# * Stop predicting when the model predicts the *end token*.\n",
    "# * And store the *attention weights for every time step*.\n",
    "# \n",
    "# Note: The encoder output is calculated only once for one input.\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "          return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "translate(u'print(\"Hello, world!\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-retail",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
