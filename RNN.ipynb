{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#TENSORFLOW\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 178010\n"
     ]
    }
   ],
   "source": [
    "with open('fra-eng/fra.txt','r') as f:\n",
    "    data = f.read()\n",
    "    print('number of samples:',len(data.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleaned_data_list = data.split('\\n')\n",
    "english_sentences = []\n",
    "french_sentences = []\n",
    "\n",
    "import random\n",
    "sampled = random.sample(uncleaned_data_list,5000)\n",
    "#sampled = uncleaned_data_list\n",
    "\n",
    "for sentence in sampled:\n",
    "    try:\n",
    "        english_sentences.append(sentence.split('\\t')[:-1][0])\n",
    "        french_sentences.append(sentence.split('\\t')[:-1][1])\n",
    "    except:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30608 English words.\n",
      "5038 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"I\" \"to\" \"you\" \"the\" \"a\" \"is\" \"Tom\" \"of\" \"in\" \"that\"\n",
      "\n",
      "33427 French words.\n",
      "6528 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"de\" \"Je\" \"?\" \"pas\" \"que\" \"Ã \" \"ne\" \"la\" \"le\" \"Il\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "\n",
    "\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pad(pad):\n",
    "    tokens = [\n",
    "        [i for i in range(4)],\n",
    "        [i for i in range(6)],\n",
    "        [i for i in range(3)]]\n",
    "    padded_tokens = pad(tokens)\n",
    "    padding_id = padded_tokens[0][-1]\n",
    "    true_padded_tokens = np.array([\n",
    "        [i for i in range(4)] + [padding_id]*2,\n",
    "        [i for i in range(6)],\n",
    "        [i for i in range(3)] + [padding_id]*3])\n",
    "    assert isinstance(padded_tokens, np.ndarray),\\\n",
    "        'Pad returned the wrong type.  Found {} type, expected numpy array type.'\n",
    "    assert np.all(padded_tokens == true_padded_tokens), 'Pad returned the wrong results.'\n",
    "\n",
    "    padded_tokens_using_length = pad(tokens, 9)\n",
    "    assert np.all(padded_tokens_using_length == np.concatenate((true_padded_tokens, np.full((3, 3), padding_id)), axis=1)),\\\n",
    "        'Using length argument return incorrect results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
    "test_pad(pad)\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 44\n",
      "Max French sentence length: 55\n",
      "English vocabulary size: 3403\n",
      "French vocabulary size: 5151\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_to_text() function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "print('logits_to_text() function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "# list all data in history\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "400/400 [==============================] - 22s 56ms/step - loss: 1.7314 - accuracy: 0.8759 - val_loss: 0.8793 - val_accuracy: 0.8784\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.8584 - accuracy: 0.8791 - val_loss: 0.8719 - val_accuracy: 0.8816\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.8405 - accuracy: 0.8821 - val_loss: 0.8665 - val_accuracy: 0.8824\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 23s 58ms/step - loss: 0.8245 - accuracy: 0.8825 - val_loss: 0.8601 - val_accuracy: 0.8835\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 23s 59ms/step - loss: 0.8097 - accuracy: 0.8832 - val_loss: 0.8537 - val_accuracy: 0.8844\n",
      "Epoch 6/25\n",
      "400/400 [==============================] - 22s 56ms/step - loss: 0.7959 - accuracy: 0.8845 - val_loss: 0.8487 - val_accuracy: 0.8852\n",
      "Epoch 7/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7835 - accuracy: 0.8856 - val_loss: 0.8465 - val_accuracy: 0.8865\n",
      "Epoch 8/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7727 - accuracy: 0.8864 - val_loss: 0.8433 - val_accuracy: 0.8869\n",
      "Epoch 9/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7625 - accuracy: 0.8864 - val_loss: 0.8431 - val_accuracy: 0.8872\n",
      "Epoch 10/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7534 - accuracy: 0.8866 - val_loss: 0.8428 - val_accuracy: 0.8875\n",
      "Epoch 11/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7445 - accuracy: 0.8871 - val_loss: 0.8437 - val_accuracy: 0.8875\n",
      "Epoch 12/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7367 - accuracy: 0.8874 - val_loss: 0.8446 - val_accuracy: 0.8873\n",
      "Epoch 13/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7293 - accuracy: 0.8875 - val_loss: 0.8451 - val_accuracy: 0.8884\n",
      "Epoch 14/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7223 - accuracy: 0.8878 - val_loss: 0.8460 - val_accuracy: 0.8867\n",
      "Epoch 15/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7157 - accuracy: 0.8878 - val_loss: 0.8476 - val_accuracy: 0.8868\n",
      "Epoch 16/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7097 - accuracy: 0.8880 - val_loss: 0.8470 - val_accuracy: 0.8885\n",
      "Epoch 17/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.7040 - accuracy: 0.8882 - val_loss: 0.8474 - val_accuracy: 0.8875\n",
      "Epoch 18/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.6984 - accuracy: 0.8882 - val_loss: 0.8471 - val_accuracy: 0.8870\n",
      "Epoch 19/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.6930 - accuracy: 0.8884 - val_loss: 0.8478 - val_accuracy: 0.8879\n",
      "Epoch 20/25\n",
      "400/400 [==============================] - 22s 56ms/step - loss: 0.6885 - accuracy: 0.8884 - val_loss: 0.8479 - val_accuracy: 0.8882\n",
      "Epoch 21/25\n",
      "400/400 [==============================] - 21s 54ms/step - loss: 0.6837 - accuracy: 0.8889 - val_loss: 0.8482 - val_accuracy: 0.8883\n",
      "Epoch 22/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6791 - accuracy: 0.8890 - val_loss: 0.8492 - val_accuracy: 0.8891\n",
      "Epoch 23/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6750 - accuracy: 0.8891 - val_loss: 0.8493 - val_accuracy: 0.8891\n",
      "Epoch 24/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6710 - accuracy: 0.8892 - val_loss: 0.8506 - val_accuracy: 0.8893\n",
      "Epoch 25/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6672 - accuracy: 0.8896 - val_loss: 0.8506 - val_accuracy: 0.8894\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc1d8512ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "elle a de <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def simple_model(input_shape, output_sequence_length, output_vocab_size):\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    input_seq = Input(input_shape[1:])\n",
    "    rnn = GRU(64, return_sequences = True)(input_seq)\n",
    "    logits = TimeDistributed(Dense(output_vocab_size+1))(rnn)\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    \n",
    "    model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#tests.test_simple_model(simple_model)\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "# Train the neural network\n",
    "\n",
    "\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    french_vocab_size+1)\n",
    "\n",
    "#simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=10, epochs=10, validation_split=0.2)\n",
    "history = simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=10, epochs=25, validation_split=0.2)\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.6871 - accuracy: 0.8741 - val_loss: 0.9504 - val_accuracy: 0.8784\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.8808 - accuracy: 0.8807 - val_loss: 0.8552 - val_accuracy: 0.8823\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.8211 - accuracy: 0.8830 - val_loss: 0.8304 - val_accuracy: 0.8840\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.7911 - accuracy: 0.8860 - val_loss: 0.8173 - val_accuracy: 0.8878\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.7631 - accuracy: 0.8896 - val_loss: 0.8055 - val_accuracy: 0.8903\n",
      "Epoch 6/25\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 0.7344 - accuracy: 0.8923 - val_loss: 0.7910 - val_accuracy: 0.8925\n",
      "Epoch 7/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.7058 - accuracy: 0.8949 - val_loss: 0.7827 - val_accuracy: 0.8946\n",
      "Epoch 8/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.6790 - accuracy: 0.8967 - val_loss: 0.7757 - val_accuracy: 0.8950\n",
      "Epoch 9/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.6545 - accuracy: 0.8985 - val_loss: 0.7756 - val_accuracy: 0.8962\n",
      "Epoch 10/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.6324 - accuracy: 0.8995 - val_loss: 0.7728 - val_accuracy: 0.8958\n",
      "Epoch 11/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.6105 - accuracy: 0.9009 - val_loss: 0.7740 - val_accuracy: 0.8965\n",
      "Epoch 12/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.5896 - accuracy: 0.9021 - val_loss: 0.7718 - val_accuracy: 0.8979\n",
      "Epoch 13/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.5700 - accuracy: 0.9034 - val_loss: 0.7701 - val_accuracy: 0.8975\n",
      "Epoch 14/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.5513 - accuracy: 0.9048 - val_loss: 0.7735 - val_accuracy: 0.8981\n",
      "Epoch 15/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.5337 - accuracy: 0.9055 - val_loss: 0.7738 - val_accuracy: 0.8983\n",
      "Epoch 16/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.5164 - accuracy: 0.9071 - val_loss: 0.7799 - val_accuracy: 0.8967\n",
      "Epoch 17/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.5000 - accuracy: 0.9080 - val_loss: 0.7786 - val_accuracy: 0.8982\n",
      "Epoch 18/25\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.4847 - accuracy: 0.9097 - val_loss: 0.7814 - val_accuracy: 0.8977\n",
      "Epoch 19/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.4698 - accuracy: 0.9109 - val_loss: 0.7834 - val_accuracy: 0.8983\n",
      "Epoch 20/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.4552 - accuracy: 0.9124 - val_loss: 0.7870 - val_accuracy: 0.8981\n",
      "Epoch 21/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.4416 - accuracy: 0.9137 - val_loss: 0.7894 - val_accuracy: 0.8981\n",
      "Epoch 22/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.4286 - accuracy: 0.9150 - val_loss: 0.7916 - val_accuracy: 0.8983\n",
      "Epoch 23/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.4165 - accuracy: 0.9163 - val_loss: 0.7939 - val_accuracy: 0.8977\n",
      "Epoch 24/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.4042 - accuracy: 0.9178 - val_loss: 0.7980 - val_accuracy: 0.8980\n",
      "Epoch 25/25\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.3920 - accuracy: 0.9191 - val_loss: 0.8024 - val_accuracy: 0.8977\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "def embed_model(input_shape, output_sequence_length, french_vocab_size):\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    #em can only be used in first layer --> Keras Documentation\n",
    "    model.add(Embedding(french_vocab_size, 64, input_length=input_shape[1]))\n",
    "    model.add(GRU(64, return_sequences=True, activation=\"tanh\"))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation=\"softmax\")))\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "embeded_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    french_vocab_size+1)\n",
    "\n",
    "\n",
    "history = embeded_model.fit(tmp_x, preproc_french_sentences, batch_size=10, epochs=25, validation_split=0.2)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 1.2547 - accuracy: 0.8807 - val_loss: 0.8512 - val_accuracy: 0.8839\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8153 - accuracy: 0.8845 - val_loss: 0.8541 - val_accuracy: 0.8853\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.7926 - accuracy: 0.8856 - val_loss: 0.8481 - val_accuracy: 0.8867\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.7729 - accuracy: 0.8867 - val_loss: 0.8465 - val_accuracy: 0.8870\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 22s 54ms/step - loss: 0.7557 - accuracy: 0.8875 - val_loss: 0.8467 - val_accuracy: 0.8881\n",
      "Epoch 6/25\n",
      "400/400 [==============================] - 21s 54ms/step - loss: 0.7380 - accuracy: 0.8881 - val_loss: 0.8438 - val_accuracy: 0.8891\n",
      "Epoch 7/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.7191 - accuracy: 0.8892 - val_loss: 0.8420 - val_accuracy: 0.8890\n",
      "Epoch 8/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.7013 - accuracy: 0.8896 - val_loss: 0.8425 - val_accuracy: 0.8892\n",
      "Epoch 9/25\n",
      "400/400 [==============================] - 22s 54ms/step - loss: 0.6837 - accuracy: 0.8903 - val_loss: 0.8403 - val_accuracy: 0.8902\n",
      "Epoch 10/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6673 - accuracy: 0.8909 - val_loss: 0.8406 - val_accuracy: 0.8902\n",
      "Epoch 11/25\n",
      "400/400 [==============================] - 22s 54ms/step - loss: 0.6502 - accuracy: 0.8917 - val_loss: 0.8386 - val_accuracy: 0.8908\n",
      "Epoch 12/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.6346 - accuracy: 0.8921 - val_loss: 0.8388 - val_accuracy: 0.8914\n",
      "Epoch 13/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.6171 - accuracy: 0.8931 - val_loss: 0.8426 - val_accuracy: 0.8906\n",
      "Epoch 14/25\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6049 - accuracy: 0.8935 - val_loss: 0.8430 - val_accuracy: 0.8917\n",
      "Epoch 15/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5913 - accuracy: 0.8943 - val_loss: 0.8457 - val_accuracy: 0.8910\n",
      "Epoch 16/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5775 - accuracy: 0.8956 - val_loss: 0.8443 - val_accuracy: 0.8910\n",
      "Epoch 17/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5652 - accuracy: 0.8965 - val_loss: 0.8458 - val_accuracy: 0.8913\n",
      "Epoch 18/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5537 - accuracy: 0.8977 - val_loss: 0.8499 - val_accuracy: 0.8919\n",
      "Epoch 19/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5409 - accuracy: 0.8985 - val_loss: 0.8517 - val_accuracy: 0.8910\n",
      "Epoch 20/25\n",
      "400/400 [==============================] - 22s 54ms/step - loss: 0.5319 - accuracy: 0.8995 - val_loss: 0.8535 - val_accuracy: 0.8913\n",
      "Epoch 21/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5209 - accuracy: 0.9006 - val_loss: 0.8568 - val_accuracy: 0.8907\n",
      "Epoch 22/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5108 - accuracy: 0.9014 - val_loss: 0.8566 - val_accuracy: 0.8906\n",
      "Epoch 23/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5046 - accuracy: 0.9022 - val_loss: 0.8577 - val_accuracy: 0.8915\n",
      "Epoch 24/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4959 - accuracy: 0.9029 - val_loss: 0.8617 - val_accuracy: 0.8902\n",
      "Epoch 25/25\n",
      "400/400 [==============================] - 21s 54ms/step - loss: 0.4862 - accuracy: 0.9040 - val_loss: 0.8618 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "def bd_model(input_shape, output_sequence_length, french_vocab_size):\n",
    "   \n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), input_shape = input_shape[1:]))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
    "    \n",
    "    model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "bidi_model = bd_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "\n",
    "history = bidi_model.fit(tmp_x, preproc_french_sentences, batch_size=10, epochs=25, validation_split=0.2)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 1.2840 - accuracy: 0.8801 - val_loss: 0.8998 - val_accuracy: 0.8819\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8781 - accuracy: 0.8821 - val_loss: 0.8948 - val_accuracy: 0.8819\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.8651 - accuracy: 0.8823 - val_loss: 0.9001 - val_accuracy: 0.8826\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8564 - accuracy: 0.8834 - val_loss: 0.8974 - val_accuracy: 0.8833\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8489 - accuracy: 0.8833 - val_loss: 0.8975 - val_accuracy: 0.8837\n",
      "Epoch 6/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8436 - accuracy: 0.8838 - val_loss: 0.9006 - val_accuracy: 0.8837\n",
      "Epoch 7/25\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.8408 - accuracy: 0.8839 - val_loss: 0.9138 - val_accuracy: 0.8837\n",
      "Epoch 8/25\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.8375 - accuracy: 0.8839 - val_loss: 0.9068 - val_accuracy: 0.8837\n",
      "Epoch 9/25\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.8346 - accuracy: 0.8838 - val_loss: 0.9094 - val_accuracy: 0.8838\n",
      "Epoch 10/25\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.8323 - accuracy: 0.8839 - val_loss: 0.9087 - val_accuracy: 0.8837\n",
      "Epoch 11/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8298 - accuracy: 0.8839 - val_loss: 0.9137 - val_accuracy: 0.8837\n",
      "Epoch 12/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8278 - accuracy: 0.8839 - val_loss: 0.9182 - val_accuracy: 0.8837\n",
      "Epoch 13/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8253 - accuracy: 0.8839 - val_loss: 0.9177 - val_accuracy: 0.8837\n",
      "Epoch 14/25\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8237 - accuracy: 0.8839 - val_loss: 0.9188 - val_accuracy: 0.8838\n",
      "Epoch 15/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8214 - accuracy: 0.8839 - val_loss: 0.9238 - val_accuracy: 0.8838\n",
      "Epoch 16/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8200 - accuracy: 0.8837 - val_loss: 0.9239 - val_accuracy: 0.8838\n",
      "Epoch 17/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8182 - accuracy: 0.8839 - val_loss: 0.9247 - val_accuracy: 0.8838\n",
      "Epoch 18/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8170 - accuracy: 0.8839 - val_loss: 0.9266 - val_accuracy: 0.8838\n",
      "Epoch 19/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8156 - accuracy: 0.8838 - val_loss: 0.9266 - val_accuracy: 0.8837\n",
      "Epoch 20/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8140 - accuracy: 0.8839 - val_loss: 0.9274 - val_accuracy: 0.8837\n",
      "Epoch 21/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8120 - accuracy: 0.8839 - val_loss: 0.9297 - val_accuracy: 0.8838\n",
      "Epoch 22/25\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.8102 - accuracy: 0.8839 - val_loss: 0.9299 - val_accuracy: 0.8837\n",
      "Epoch 23/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8091 - accuracy: 0.8840 - val_loss: 0.9309 - val_accuracy: 0.8837\n",
      "Epoch 24/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8074 - accuracy: 0.8838 - val_loss: 0.9322 - val_accuracy: 0.8837\n",
      "Epoch 25/25\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8063 - accuracy: 0.8839 - val_loss: 0.9337 - val_accuracy: 0.8837\n"
     ]
    }
   ],
   "source": [
    "def encdec_model(input_shape, output_sequence_length, french_vocab_size):\n",
    "  \n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape = input_shape[1:], return_sequences = False))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(GRU(128, return_sequences = True))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
    "    \n",
    "    model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "tmp_x = pad(preproc_english_sentences)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[1], 1))\n",
    "encodeco_model = encdec_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "history = encodeco_model.fit(tmp_x, preproc_french_sentences, batch_size=10, epochs=25, validation_split=0.2)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.1098 - accuracy: 0.8792"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[6,6] = 3403 is not in [0, 3403)\n\t [[node sequential_14/embedding_5/embedding_lookup (defined at <ipython-input-171-7dc2bef198c0>:26) ]] [Op:__inference_test_function_252710]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_14/embedding_5/embedding_lookup:\n sequential_14/embedding_5/embedding_lookup/251065 (defined at /opt/anaconda3/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-7dc2bef198c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustosm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc_french_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[6,6] = 3403 is not in [0, 3403)\n\t [[node sequential_14/embedding_5/embedding_lookup (defined at <ipython-input-171-7dc2bef198c0>:26) ]] [Op:__inference_test_function_252710]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_14/embedding_5/embedding_lookup:\n sequential_14/embedding_5/embedding_lookup/251065 (defined at /opt/anaconda3/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "def custom_model(input_shape, output_sequence_length, french_vocab_size):\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=english_vocab_size,output_dim=128,input_length=input_shape[1]))\n",
    "    model.add(Bidirectional(GRU(256,return_sequences=False)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(256,return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size,activation='softmax')))\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "tmp_x = pad(preproc_english_sentences)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[1], 1))\n",
    "custosm = model_custom(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "\n",
    "history = custosm.fit(tmp_x, preproc_french_sentences, batch_size = 10, epochs = 25, validation_split = 0.2)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 44]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-1dab1e5c3933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbidi_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#m = encodeco_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreproc_english_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc_french_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrench_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-160-1dab1e5c3933>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(x, y, x_tk, y_tk, model, sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_id_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 44]\n"
     ]
    }
   ],
   "source": [
    "def translate(x, y, x_tk, y_tk, model, sentence):\n",
    "    tmp_X = pad(preproc_english_sentences)\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "    \n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    \n",
    "    predictions = model.predict(sentence)\n",
    "    output = [y_id_to_word[np.argmax(x)] for x in predictions[0]]\n",
    "    \n",
    "    translation = []\n",
    "    for word in output:\n",
    "        if word == '<PAD>':\n",
    "            break\n",
    "        else:\n",
    "            translation.append(word)\n",
    "    print(' '.join(translation))\n",
    "\n",
    "sentence = 'where am i from'\n",
    "#m = simple_rnn_model\n",
    "#m = embeded_model\n",
    "m = bidi_model\n",
    "#m = encodeco_model\n",
    "translate(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer, m, sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
